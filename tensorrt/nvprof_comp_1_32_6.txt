==20979== NVPROF is profiling process 20979, command: ./mbnet
==20979== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==20979== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==20979== Profiling application: ./mbnet
==20979== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   94.64%  291.89ms     10005  29.174us  27.745us  49.696us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.39%  1.2055ms         3  401.82us  398.41us  407.14us  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.24%  736.05us        10  73.604us  49.249us  100.03us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.24%  727.63us        17  42.801us  41.665us  44.833us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.21%  659.92us         3  219.97us  218.72us  222.15us  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.18%  545.54us        10  54.554us  52.129us  59.681us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.18%  543.31us         4  135.83us  129.89us  149.12us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.18%  542.79us         4  135.70us  129.51us  149.28us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.17%  536.81us         4  134.20us  128.26us  148.71us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.17%  534.60us         4  133.65us  125.92us  156.48us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.17%  529.48us         4  132.37us  123.52us  149.60us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.17%  527.85us         4  131.96us  126.27us  145.76us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.17%  525.64us         5  105.13us  79.682us  141.12us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.17%  517.64us         4  129.41us  123.84us  141.92us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.16%  508.20us         4  127.05us  121.95us  141.73us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.15%  460.14us         5  92.027us  66.401us  113.12us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.13%  396.39us         4  99.098us  93.026us  115.52us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.12%  376.84us         7  53.834us  47.713us  60.801us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.12%  366.02us         5  73.204us  65.601us  92.801us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.11%  328.68us        83  3.9590us     704ns  10.976us  [CUDA memset]
                    0.10%  295.75us         4  73.937us  70.241us  84.322us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.09%  292.10us         4  73.025us  67.522us  84.642us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.09%  288.96us         4  72.241us  67.041us  83.457us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.09%  281.22us         4  70.305us  66.625us  80.706us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.09%  273.16us         4  68.289us  65.601us  74.785us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.09%  272.68us         4  68.169us  65.121us  75.201us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.09%  267.65us         4  66.913us  64.481us  73.921us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.09%  263.81us         5  52.762us  44.705us  57.985us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.08%  261.12us         4  65.281us  62.401us  72.161us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.08%  258.85us         4  64.713us  63.106us  68.001us  void cudnn::cnn::conv2d_grouped_direct_kernel<bool=0, bool=1, bool=0, bool=0, int=0, int=0, int, float, float, float, float, float, float>(cudnn::cnn::GroupedDirectFpropParams, float const *, float const *, float*, float, float*, float const * const *, float const *, cudnnActivationStruct)
                    0.08%  240.71us         4  60.177us  52.033us  81.633us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.08%  238.95us         4  59.737us  51.393us  79.682us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.07%  224.52us         4  56.129us  48.161us  76.482us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.07%  223.56us         4  55.889us  47.105us  76.738us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.07%  220.10us         5  44.020us  41.441us  51.233us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  197.29us        48  4.1100us  3.2640us  6.2720us  [CUDA memcpy DtoD]
                    0.06%  189.41us         6  31.568us  24.864us  44.800us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.06%  184.16us         4  46.041us  43.105us  54.337us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.06%  182.69us         4  45.672us  42.561us  54.305us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.06%  180.52us         4  45.128us  41.697us  55.041us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.06%  180.36us        24  7.5140us  7.2000us  8.3530us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.06%  176.48us         6  29.414us  21.921us  43.041us  void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.06%  175.17us         4  43.792us  39.488us  56.641us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    0.05%  167.01us       118  1.4150us     480ns  5.0240us  [CUDA memcpy HtoD]
                    0.03%  101.63us         4  25.408us  20.033us  39.841us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig1DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=1, int=256, int=1, int=64, char=4, bool=1, bool=0, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.02%  71.362us         3  23.787us  18.145us  33.377us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.02%  70.305us         3  23.435us  18.880us  32.384us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.02%  61.921us        26  2.3810us  2.0800us  5.5040us  [CUDA memcpy DtoH]
                    0.02%  58.561us         4  14.640us  13.280us  18.561us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.01%  45.280us         4  11.320us  9.2800us  17.152us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.00%  15.296us         3  5.0980us  3.9360us  7.2000us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
      API calls:   27.86%  4.57558s       195  23.464ms  1.3760us  1.32972s  cudaFree
                   18.88%  3.10014s       669  4.6340ms  8.7040us  166.60ms  cuModuleUnload
                   18.39%  3.02085s        34  88.849ms  8.2240us  3.02021s  cudaMemGetInfo
                   16.79%  2.75711s        33  83.549ms  2.8480us  2.75622s  cudaStreamCreateWithFlags
                   13.98%  2.29606s     10241  224.20us  29.760us  1.93505s  cudaLaunchKernel
                    2.93%  480.50ms     10050  47.811us  3.1680us  2.2516ms  cudaStreamSynchronize
                    0.49%  80.049ms       179  447.20us  9.8240us  10.485ms  cudaEventSynchronize
                    0.24%  40.234ms     10400  3.8680us  1.6320us  145.41us  cudaEventRecord
                    0.17%  27.397ms       156  175.62us  13.536us  1.0405ms  cudaMalloc
                    0.10%  16.152ms       228  70.843us     864ns  422.21us  cudaMemcpyAsync
                    0.05%  7.5394ms     10411     724ns     512ns  24.481us  cudaGetLastError
                    0.03%  5.1552ms       179  28.800us  13.280us  182.15us  cudaStreamAddCallback
                    0.02%  3.2218ms        83  38.816us  14.016us  117.54us  cudaMemsetAsync
                    0.01%  2.1588ms         4  539.71us  79.905us  698.69us  cudaHostAlloc
                    0.01%  1.8629ms        15  124.19us  30.784us  584.51us  cudaMemcpy
                    0.01%  1.3319ms       944  1.4100us     416ns  163.78us  cuDeviceGetAttribute
                    0.01%  1.2615ms       179  7.0470us  3.8400us  18.240us  cudaEventElapsedTime
                    0.01%  1.2486ms         4  312.15us  92.576us  463.78us  cudaFreeHost
                    0.01%  1.0254ms       385  2.6630us     864ns  49.856us  cudaDeviceGetAttribute
                    0.00%  622.43us        17  36.613us  27.136us  89.920us  cudaGetDeviceProperties
                    0.00%  502.98us        16  31.436us  2.7840us  436.13us  cudaStreamCreateWithPriority
                    0.00%  438.34us       189  2.3190us  1.3120us  32.864us  cudaEventDestroy
                    0.00%  429.03us       186  2.3060us  1.5040us  10.112us  cudaEventCreateWithFlags
                    0.00%  395.74us        11  35.976us  29.376us  50.304us  cudaCreateTextureObject
                    0.00%  371.17us        51  7.2770us  3.7760us  27.328us  cudaStreamDestroy
                    0.00%  266.50us        28  9.5170us  4.5120us  27.232us  cudaDeviceSynchronize
                    0.00%  235.84us        10  23.584us  12.608us  78.528us  cuDeviceTotalMem
                    0.00%  211.49us        60  3.5240us  1.7600us  42.112us  cudaStreamWaitEvent
                    0.00%  210.56us        32  6.5800us  1.2480us  58.368us  cudaGetDevice
                    0.00%  176.29us        11  16.026us  9.6640us  48.384us  cudaDestroyTextureObject
                    0.00%  62.720us         9  6.9680us  4.9920us  17.728us  cuInit
                    0.00%  41.632us         9  4.6250us  1.6640us  17.920us  cuDriverGetVersion
                    0.00%  32.096us         2  16.048us  13.632us  18.464us  cudaStreamCreate
                    0.00%  27.904us         3  9.3010us  5.8880us  13.952us  cudaEventCreate
                    0.00%  23.904us        10  2.3900us  1.5360us  6.7200us  cuDeviceGetName
                    0.00%  22.912us        12  1.9090us     800ns  6.3040us  cuDeviceGetCount
                    0.00%  21.568us         4  5.3920us  3.5520us  6.2400us  cudaHostGetDevicePointer
                    0.00%  17.120us        11  1.5560us     960ns  3.8720us  cuDeviceGet
                    0.00%  16.992us         8  2.1240us  1.8240us  2.6880us  cuDevicePrimaryCtxRelease
                    0.00%  13.376us        13  1.0280us     480ns  2.5600us  cudaGetDeviceCount
                    0.00%  11.968us         4  2.9920us  2.1760us  4.8640us  cudaDeviceGetStreamPriorityRange
                    0.00%  9.9520us        11     904ns     608ns  1.4080us  cudaCreateChannelDesc
                    0.00%  8.6400us        10     864ns     544ns  1.6640us  cuDeviceGetUuid
                    0.00%  6.2080us        10     620ns     416ns     832ns  cudaRuntimeGetVersion
                    0.00%  5.3120us         8     664ns     576ns     960ns  cudaPeekAtLastError
                    0.00%  2.9120us         5     582ns     544ns     640ns  cudaDriverGetVersion

==20979== NVTX result:
==20979==   Thread "<unnamed>" (id = 2137732912)
==20979==     Domain "TensorRT"
==20979==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  407.10ms     10000  40.710us  35.104us  1.1256ms  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  291.69ms     10000  29.168us  27.745us  49.696us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  347.06ms     10000  34.706us  29.760us  1.1197ms  cudaLaunchKernel

==20979==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  985.41ms     10000  98.540us  73.153us  2.3194ms  ExecutionContext::execute
 GPU activities:  100.00%  291.69ms     10000  29.168us  27.745us  49.696us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  347.06ms     10000  34.706us  29.760us  1.1197ms  cudaLaunchKernel

